 return-path email delivery-d sun sep number number number from email (tim peters) date sun number sep number number number subject [spambayes] test set in-reply-to email message-id email [guido]  i *meant* to say that they were number clue cancel out by number  clue but that wrong too it look i haven't grokk this part of  your code yet this one has way more than number clue and it seem the  classifi basic end up count way more number than number clue  and no other made it into the list i thought it was look for  clue with valu in between appar it found none that weren't  exact number there a brief discuss of this befor the definit of max_discrimin all clue with prob min_spamprob and max_spamprob are save in min and max list and all other clue are fed into the nbest heap then the shorter of the min and max list cancel out the same number of clue in the longer list whatev remain of the longer list (if anything) is then fed into the nbest heap too but no more than max_discrimin of them in no case do more than max_discrimin clue enter into the final probabl calcul but all of the min and max list go into the list of clue (els you'd have no clue that massiv cancel was occur and massiv cancel may yet turn out to be a hook to signal that manual review is needed) in your specif case the excess of clue in the longer max_spamprob list push everyth els out of the nbest heap and that whi you didn't see anyth other than number and number befor ad these special list the outcom when face with mani number and number clue was too often a coin toss whichev flavor just happen to appear number + number time first determin the final outcom  that sure set the record for longest list of cancel extrem clue  this happen to be the longest one but there were quit a few  similar one i just beat it  a token scheme that fold case and ignor punctuat and strip a trail s from word and save both word bigram and word unigram turn up a low-prob veri long spam with a list of number number clue and number number clue yike  i wonder if there anyth we can learn from look at the clue and the  html it was heavili marked-up html with ad in the sidebar but the bodi  text was a serious discuss of "oo and soft coding" with lot of high  technic word as clue (includ zope and zeo) no matter how often it say zope it get onli one number clue from do so ditto for zeo in contrast html markup has mani uniqu "words" that get number btw this is a clear case where the assumpt of conditionally-independ word probabl is utter bogus -- e.g. the probabl that  appear in a messag is high correl with the prob of  appear by treat them as independ naiv bay grossli misjudg the probabl that both appear and the onli thing you get in return is someth that can actual be comput  read the "what about html?" section in tokenizer.pi from the veri start i'v been investig what would work best for the mail list host at python.org and html decor have so far been too strong a clue to justifi ignor it in that specif context i haven't done anyth gear toward person email includ the case of non-mailing-list email that happen to go through python.org i'd prefer to strip html tag from everyth but last time i tri that it still had bad effect on the error rate in my corpora (the full test result with and without html tag strip is includ in the "what about html?" comment block) but as the comment block also say # xxx so if anoth way is found to slash the f-n rate the decis here # xxx not to strip html from html-on msgs should be revisit and we'v sinc done sever thing that gave signific f-n rate reduct i should test that again now  are there ani minable-but-unmin header line in your corpus left almost all of them -- apart from mime decor that appear in both header and bodi (like content-type) the *only* header line the base token look at now are subject from x-mailer and organ  or do we have to start with a differ corpus befor we can make  progress there i would need differ data yes my ham is too pollut with mailman header decor (which i may or may not be abl to clean out but fudg the data is a mortal sin and i haven't chang a byte so far) and my spam too pollut with header clue about the fellow who collect it in particular i have to skip to and receiv header now and i suspect they'r go to be veri valuabl in real life (for exampl i don't even catch "undisclos recipients" in the to header now!)  ..  no sorri these were all of the follow structur   multipart/mix  text/plain (brief text plus url(s))  text/html (long html copi from website) ah that explain whi the html tag didn't get strip i'd again offer to add an option argument to tokenize() so that they'd get strip here too but if it get gloss over a third time that would feel too much like a loss   this seem confus jeremi didn't use my train classifi pickl  he train his own classifi from scratch on his own corpora  ..  i think it still corpus size i report on test i ran with random sampl of number spam and number ham from my corpus (that mean train on set of those size as well as predict on set of those sizes) and while that did harm the error rate the error rate i saw were still much better than jeremi report when use number of each ah a full test run just finish on the token scheme that fold case and ignor punctuat and strip a trail s from word and save both word bigram and word unigram this is the code # token everyth in the bodi lastw = '' for w in word_re.findall(text) n = len(w) # make sure this rang match in tokenize_word() if number  n  number if number == s w = number yield w if lastw yield lastw + w lastw = w + ' ' elif n  number lastw = '' for t in tokenize_word(w) yield t where word_r = number this at least doubl the process size over what done now it help the f-n rate signific but probabl hurt the f-p rate (the f-p rate is too low with onli number ham per run to be confid about chang of such small *absolute* magnitud -- percent is a singl messag in the f-p table) fals posit percentag number number tie number number lost +(was number number number lost percent number number won percent number number won percent number number lost +(was number number number lost percent number number tie number number lost percent number number won percent number number lost percent number number won percent number number tie number number lost +(was number number number lost +(was number number number won percent number number lost percent number number tie number number lost percent number number lost percent won number time tie number time lost number time total uniqu fp went from number to number fals negat percentag number number won percent number number won percent number number won percent number number tie number number won percent number number won percent number number lost percent number number won percent number number won percent number number won percent number number won percent number number won percent number number won percent number number won percent number number won percent number number won percent number number lost percent number number tie number number won percent number number lost percent won number time tie number time lost number time total uniqu fn went from number to number