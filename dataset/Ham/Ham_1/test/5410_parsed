 return-path email delivery-d thu sep number number number from email (neil schemenauer) date thu number sep number number number subject [spambayes] all but one test in-reply-to email refer email email message-id email tim peter wrote  i'v run no experi on train set size yet and won't hazard a guess  as to how much is enough i'm near certain that the number i'v been  use is way more than enough though okay i believ you  each call to learn() and to unlearn() comput a new probabl for everi  word in the databas there an offici way to avoid that in the first  two loop e.g   for msg in spam  gb.learn(msg true false)  gb.update_probabilities() i did that it still realli slow when you have thousand of messag  in each of the last two loop the total # of ham and total # of spam in the  "learned" set is invari across loop trip and you *could* break into the  abstract to exploit that the onli probabl that actual chang  across those loop trip are those associ with the word in msg then  the runtim for each trip would be proport to the # of word in the msg  rather than the number of word in the databas i hadn't tri that i figur it was better to find out if "all but one" test had ani appreci valu it look like it doesn't so i'll forget about it  anoth area for potenti fruit studi it clear that the  highest-valu indic usual appear "early" in msgs and for spam  there an actual reason for that advertis has to strive to get your  attent earli so for exampl if we onli bother to token the first  percent of a msg would result get wors spammer could exploit this includ a larg mime part at the begin of the messag in pratic that would probabl work fine  sometim an on-top messag start well but then rambl never i rememb the time when i was ten year old and went down to the fish hole with my buddi this guy name gordon had a realli huge head wait mayb that was joe well no matter as i recal it was a hot day and everyon was tired...human growth hormone...girl with huge breasts...blah blah blah.....